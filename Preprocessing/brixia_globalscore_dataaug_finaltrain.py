# -*- coding: utf-8 -*-
"""Brixia_GlobalScore_DataAug_FinalTrain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nl1u92LudAnCu_HjpA-jCZYwrXwwfNWQ
"""

## Author: Vignesh Kannan
## Notebook Objective:
## To use the COVID Images from Brixia and use the associated Brixia scores to get a prediction.
## This Notebook will use data augmentation!
## Model Specifically for Brixia Files.

## Checked: May 3rd

"""## Libraries

"""

from __future__ import print_function, division
import numpy as np
import time
import os 
import copy
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
import glob
import pandas as pd
import csv
from PIL import Image, ImageOps
import cv2
from collections import OrderedDict

import torch 
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torchvision, torchsummary
from torchvision import datasets, models, transforms as T
from torch.utils.data import Dataset, DataLoader, TensorDataset
from torch.utils.tensorboard import SummaryWriter

## XRay Vision Model
## Downloading Torch XRay vision Models
!pip install torchxrayvision
import torchxrayvision as xrv

"""## Data Related

"""

## To access the drive files!
from google.colab import drive
drive.mount("/content/drive")

def set_state(random_seed):
  np.random.seed(random_seed)
  torch.manual_seed(random_seed)

"""## Hyperparam

"""

## Hyperparams!
#STEP_FLAG = True
STEP_FLAG = False
EPOCHS = 150
BATCH_SIZE = 128
LEARNING_RATE = 0.01
RANDOM_STATE = 7
MODEL_NAME = "_".join(("BRIXIA_GlobalScore_RS"+str(RANDOM_STATE),"EPOCHS", str(EPOCHS),"Brixia_1k_DataAug_FinalTrain"))
MODEL_PATH = "/content/drive/MyDrive/Brixia-306/Model"
set_state(RANDOM_STATE)

print(MODEL_NAME)

"""## EDA and Preprocessing"""

import albumentations as A
from albumentations.pytorch import ToTensor

# aug_kwargs:
#   HorizontalFlip: {"p": 0.5}
#   ShiftScaleRotate: {"scale_limit": 0.15, "rotate_limit": 10, "p": 0.5}
#   RandomBrightnessContrast: {"p": 0.5}
#   CoarseDropout: {"max_holes": 8, "max_height": 25, "max_width": 25, "p": 0.5}
#   Blur: {"blur_limit": [3, 7], "p": 0.5}
#   Downscale: {"scale_min": 0.25, "scale_max": 0.9, "p": 0.3}
#   RandomGamma: {"gamma_limit": [80, 120], "p": 0.6}

## Loading the dataset
IMG_DIR = "/content/drive/MyDrive/png"
data_fnames = os.listdir(IMG_DIR)
use_cols = ['Filename', 
            'BrixiaScoreGlobal']
            # 'Brixia_RegionA', 
            # 'Brixia_RegionB', 
            # 'Brixia_RegionC', 
            # 'Brixia_RegionD', 
            # 'Brixia_RegionE', 
            # 'Brixia_RegionF']
annot_train = pd.read_csv("/content/drive/MyDrive/Brixia-1.5k-experiments/BRIXIA_labels_RS7_FinalSplit7_train_Final.csv", usecols = use_cols)
annot_test = pd.read_csv("/content/drive/MyDrive/Brixia-1.5k-experiments/BRIXIA_labels_RS7_FinalSplit7_test_Final.csv", usecols = use_cols)

data_fnames[:5]

annot_train.head()

def replace_filename(df):
  """ Replace the .format to match with the specific images! """
  df['Filename'] = df['Filename'].apply(lambda x: x.split(".")[0]).apply(lambda x: ".".join((x, "png")))

replace_filename(annot_train)
replace_filename(annot_test)

## To get the annotations for those files that exist.
annot_train = annot_train.loc[annot_train['Filename'].isin(data_fnames)]
annot_test = annot_test.loc[annot_test['Filename'].isin(data_fnames)]

# brixia_cohen_covid.to_csv("Brixia_COVID_Cohen.csv")
print("Total Files Accessible for train: ", len(annot_train))
print("Total Files Accessible for test: ", len(annot_test))

def load_img(filename, target_size = 224):
  """
  Load and resize the grayscale image.
  :param filename: path/filename
  :param target_size: output shape of image
  :return: loaded images as (width, height, 1)
  """

  img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
  if img is None:
    print("File Couldn't be recognized: {}".format(filename))
    return None

  img = img / 255.0   ## Normalizing.
  img = cv2.resize(img, (target_size, target_size))
  ## To match Pytorch Requirement
  img = np.reshape(img, (1, ) + img.shape )
  # img =  torch.from_numpy(img)
  return img

def shuffle_split(X, y, test_ratio = 0.2):
  """
  Shuffle and Split Dataset
  """
  lenData = len(y)
  ind = np.random.permutation(np.arange(lenData))
  X, y = X[ind], y[ind]
  testX, testY = X[:int(lenData*test_ratio)], y[:int(lenData*test_ratio)]
  trainX, trainY = X[int(lenData*test_ratio):], y[int(lenData*test_ratio):]
  return trainX, trainY, testX, testY

## New Verion!
def get_data(img_dir, annot_data, target_size= 224 ):
  """
  Get the images and annotation for the given annotated file!
  """
  X, Y = [], []
  ## For all the images
  for idx in tqdm(annot_data.itertuples()):
    ## Loading Images:
    img = load_img(os.path.join(img_dir, idx.Filename), target_size)

    ##To do. Implement Equalize
    Y.append(idx.BrixiaScoreGlobal)  ## For the Senior Score.
    X.append(img)
  X = np.asarray(X).astype(np.float32)
  Y = np.asarray(Y).astype(np.float32) 

  return X, Y
# len_data = len(y)
# # lengths = [int(len_data*(1-test_size)), int(len_data*test_size)]
# trainX, trainY, testX, testY = shuffle_split(X, y, test_ratio = 0.1)

# # trainX, trainY = get_data(IMG_DIR, annot_data = annot_train)  ## 38s
# # valX, valY = get_data(IMG_DIR, annot_data = annot_val)    ## 15s
# testX, testY = get_data(IMG_DIR, annot_data = annot_test)   #
# print("TrainX: ", testX.shape)
# print("TrainY: ", np.shape(testY))

# class Transform_Class:
#     def __init__(self, hflip_prob: float = 0.5, ssr_prob: float = 0.5, random_bc_prob: float = 0.5):
#         self.transform = A.Compose([
#                 A.HorizontalFlip(p=hflip_prob),
#                 A.ShiftScaleRotate(
#                     shift_limit=0.0625, scale_limit=0.1, rotate_limit=5, p=ssr_prob),
#                 A.RandomBrightnessContrast(p=random_bc_prob),
#                 ToTensor()
#             ])
        
#     def __call__(self, image):
#         image = self.transform(image = image)["image"]
#         return image

# Transform_v2 = A.Compose([A.HorizontalFlip(p=0.1),
#                        A.ShiftScaleRotate(
#                            shift_limit=0.0625, scale_limit=0.1, rotate_limit=5, p=0.3),
#                        A.RandomBrightnessContrast(p=0.3),
#            ])

## Custom Dataset
class BrixiaDataset(Dataset):
  """ Dataset for Brixia CXR """

  def __init__(self, annot_file, img_dir, target_size = 224, transform = None):
    """
    Args:
      annot_file: csv file with annotations.
      img_dir: Directory to where the images are stored.
      transform: Optional Transform Applied to the same.
    """

    self.annotations = pd.DataFrame(annot_file)
    self.img_dir = img_dir
    self.transform = transform
    self.target_size = target_size

  def __len__(self):
    return len(self.annotations)

  def __getitem__(self, idx):
    if torch.is_tensor(idx):
      idx = idx.tolist()
    img_name = os.path.join(self.img_dir, self.annotations.iloc[idx, 0])
  #   img = cv2.imread(img_name, cv2.IMREAD_GRAYSCALE)
  #   if img is None:
  #     print("File Couldn't be recognized: {}".format(filename))
  #     return None

  #   # img = img / 255.0   ## Normalizing.
  #   img = cv2.resize(img, (target_size, target_size))

  # img = np.reshape(img, (1, ) + img.shape )
    img = load_img(img_name, self.target_size)
    img = torch.from_numpy(img).float()
    score = self.annotations.iloc[idx, 1]
    if self.transform:
      img = self.transform(img)
    # img = torch.tensor(np.transpose(img, (2, 0, 1)).astype(np.float32))

    return img, score

# val_data = BrixiaDataset(annot_val, 
#                          IMG_DIR, 
#                          target_size = 224, 
#                          transform = T.Compose([
#                                                 T.GaussianBlur(kernel_size = 3),
#                                                 T.RandomAutocontrast(p = 0.5),
#                                                 T.RandomAdjustSharpness(1.2, p = 0.5)
#                          ]))
# next(iter(val_data))
# type(img)
# np.shape(img)
# print(img)
# plt.imshow(sample['image'], cmap = 'gray')

transform_img = T.Compose([
                          T.GaussianBlur(kernel_size = 3),
                          T.RandomAutocontrast(p = 0.5),
                          T.RandomAdjustSharpness(1.2, p = 0.5)])
train_data = BrixiaDataset(annot_train, IMG_DIR, target_size = 224, transform = transform_img)
test_data = BrixiaDataset(annot_test, IMG_DIR, target_size = 224)

train_dl = DataLoader(train_data, BATCH_SIZE, shuffle = True, num_workers = 4)
test_dl = DataLoader(test_data, BATCH_SIZE, shuffle = False, num_workers = 4)
dataloaders = {'train': train_dl,  'test': test_dl}
data_sizes = {'train': len(train_data), 'test': len(test_data)}

data_sizes

## Creating an Instance of DataLoader!
# train_dl = DataLoader(data, batch_size = 8, shuffle = True)
# X, y = next(iter(val_dl))   ## 43s! After multiple runs. 
# ## With Four Workers: 1m 15s. First run!
# print(np.shape(X))
# print(np.shape(y))

"""## Model Related"""

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_brixia = xrv.models.DenseNet(weights = 'all')
for param in model_brixia.parameters():
  param.requires_grad = False
model_brixia.op_threshs = None
model_brixia.to(device)

# torchsummary.summary(model_brixia, (1, 224, 224))

# FFNN = nn.Sequential(
#     nn.Linear(in_features = 1024, out_features = 256),
#     nn.ELU(), 
#     nn.Linear(in_features = 256, out_features = 128),
#     nn.ELU(), 
#     nn.Linear(in_features = 128, out_features = 1))

FFNN = nn.Sequential(
    nn.Linear(in_features = 1024, out_features = 100),
    nn.Tanh(), 
    nn.Dropout(0.2),

    nn.Linear(in_features = 100, out_features = 10),
    nn.Tanh(), 
    
    nn.Linear(in_features = 10, out_features = 1))

## Method 1: Update Existing Model.
model_brixia.classifier = FFNN
model_brixia.to(device)
torchsummary.summary(model_brixia, (1, 224, 224))

"""### Versions Tried!

- V1:
    - V1_1: 512-256-128-64-1
    - V1_2: 512-256-128-1
    - V1_3: 512-256-1
    - V1_4: 512-128-32-1
    - V1_5: 512-128-1
    - V1_6: 512-1
    - Which is the best: StepLR, ExpLR?
- V2:
    - [ ]  256-128-64-32-1
    - [ ]  256-128-64-1
    - [ ]  256 - 64 - 2
    - [ ]  256-128-1
    - [ ]  256-1
    - 
- V3:
    - [ ]  128 - 64 - 32 - 1
    - [ ]  128 - 32 - 1
    - [ ]  128 - 64 - 1
    - [ ]  128 - 1
    -

## Training Function
"""

## To do: Training Script!
def train_model(model, criterion, optimizer, scheduler, dataloaders, numEpochs):
  """ Simple Train Function for PyTorch Model. Adapted from PyTorch tutorials """
  start_time = time.time()

  best_WandB = copy.deepcopy(model.state_dict())
  best_loss = np.inf 
  train_hist = {}
  model.train()
  ## For all the epochs:
  for epoch in tqdm(range(numEpochs)):
    epoch_loss = 0.0
    start_epoch = time.time()
    if epoch % 50 == 0:
      print("*"*10)
      print("Epoch {}/{}".format(epoch + 1, numEpochs))
      print("*"*10)
      ## Tracking loss
      epoch_loss = 0.0

    ## For alltrain data:
    for imgs, values in dataloaders['train']:
      imgs = imgs.to(device).float()
      values = values.to(device).float()

      ## Zero the gradients
      optimizer.zero_grad()
      outputs = model(imgs)
      loss = criterion(outputs.float(), values)
      ## Epoch Stats
      epoch_loss += loss.item() 

      ## Backprop
      loss.backward()
      optimizer.step()

    epoch_loss = epoch_loss / data_sizes['train']
    scheduler.step(epoch_loss)
    train_hist[epoch] = epoch_loss


    if epoch % 50 == 0:
      print("Train_Loss: {:.4f}\tTime: {:.4f}".format(epoch_loss, time.time() - start_epoch))
    ## Check for loss: ## We don't check for validation loss
    ## Need to write a function for rmse 


    if best_loss > epoch_loss:
      best_loss = epoch_loss
      best_WandB = copy.deepcopy(model.state_dict())
      torch.save({
          'epoch': epoch,
          'loss': epoch_loss,
          'model_state': model.state_dict(),
          'optimizer_state_dict': optimizer.state_dict()
      }, os.path.join(MODEL_PATH, MODEL_NAME+str(".pth")))
      print()
      print("Epoch: ", epoch)
      print("====> New Best Model!: {}".format(MODEL_NAME))
      print("Epoch Loss: {:.4f}".format(best_loss))
      print()
      print("*"*10)

  ## Loading best model
  print("Best MSE: {:.4f}".format(best_loss))
  print("Total Time: {:.4f}".format(time.time() - start_time)) 

  model.load_state_dict(best_WandB)
  return model, train_hist

"""## Training

"""

FLAG = 1
criterion = nn.MSELoss()
optimizer = optim.Adam([
                        {"params": model_brixia.classifier.parameters(), "lr": LEARNING_RATE},
                        {"params": model_brixia.features.parameters(), "lr": 0.0001}              
                        ], lr = LEARNING_RATE
                        )
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
if FLAG ==  0:
  lr_scheduler = optim.lr_scheduler.StepLR(optimizer, gamma = 0.1, step_size = 10)
else:
    lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_dl), eta_min=0.0)

## TODO: Tensorboard Visualization!
MODEL_NAME = 'BRIXIA_GlobalScore_RS7_EPOCHS_150_Brixia_1k_DataAug_FinalTrain' ## Change name
model_brixia.to(device)
model_brixia, train_hist = train_model(model_brixia, criterion, optimizer, lr_scheduler, dataloaders, 150)

plt.figure(figsize = (10,7))
lists = sorted(train_hist.items())
train_epoch, train_loss = zip(*lists[1:])
plt.plot(train_epoch, train_loss, label = 'Train')
plt.title(MODEL_NAME)
plt.legend()
plt.savefig(str(MODEL_NAME))



def eval_model(model, criterion, eval_loader):
  """ Simple Train Function for PyTorch Model. Adapted from PyTorch tutorials """
  start_time = time.time()
  loss_hist = {}
  model.eval()

  ## Tracking loss
  eval_loss = 0.0
  ## For Evaluation Data:
  for imgs, values in eval_loader:
      imgs = imgs.to(device)
      values = values.to(device)

      ## Zero the gradients
      optimizer.zero_grad()
      outputs = model(imgs)
      loss = criterion(outputs, values)
      eval_loss += loss.item() 

    
   

  eval_loss = eval_loss / len(eval_loader.dataset)
  print("Loss: {:.4f}\tTime: {:.4f}".format(eval_loss, time.time() - start_time))
  return eval_loss

## Testing:
print("Train: ")
train_loss = eval_model(model_brixia, criterion, train_dl)
print("Test: ")
test_out = eval_model(model_brixia, criterion, test_dl)

